{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.l1=torch.nn.Linear(63,21)\n",
    "        self.l2=torch.nn.Linear(21,5)\n",
    "        self.l3=torch.nn.Linear(5,3)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.sigmoid(self.l1(x))\n",
    "        x=self.sigmoid(self.l2(x))\n",
    "        return self.l3(x)\n",
    "\n",
    "\n",
    "model=torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardScaler(x):\n",
    "    '''data normalization based on sk[0]'''\n",
    "    x_array=np.array(x)\n",
    "    x_array-=x_array[0]\n",
    "\n",
    "    mean=np.mean(x_array)\n",
    "    std=np.std(x_array)\n",
    "\n",
    "    x_array-=mean\n",
    "    x_array/=std\n",
    "\n",
    "    x_corr=x_array.tolist()\n",
    "\n",
    "    return x_corr\n",
    "\n",
    "def Landmarks2array(hand_landmarks):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    xyz=[]\n",
    "    for i in range(0, len(hand_landmarks.landmark)):\n",
    "        x.append(hand_landmarks.landmark[i].x)\n",
    "        y.append(hand_landmarks.landmark[i].y)\n",
    "        z.append(hand_landmarks.landmark[i].z)\n",
    "\n",
    "    x=StandardScaler(x)\n",
    "    y=StandardScaler(y)\n",
    "    z=StandardScaler(z)\n",
    "\n",
    "    xyz=x+y+z\n",
    "    return np.array(xyz)\n",
    "\n",
    "def num_to01(num):\n",
    "    if (num<0): return 0\n",
    "    if (num>1): return 1\n",
    "    else: return num\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](mediapipe_handlandmarks.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_landmark=8\n",
    "end_landmark=17\n",
    "\n",
    "last_point=[]\n",
    "currunt_point=[]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width=int(cap.get(3))\n",
    "height=int(cap.get(4))\n",
    "\n",
    "board=np.ones((height,width),np.uint8)\n",
    "board*=255\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.75, min_tracking_confidence=0.75, max_num_hands=1) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      continue\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks: # with hands\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image,hand_landmarks,mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        inputs=torch.from_numpy(Landmarks2array(hand_landmarks)).float()\n",
    "        # calculate output for gesture classification\n",
    "        outputs=model(inputs)\n",
    "        _,predicted=torch.max(outputs.data,dim=0)\n",
    "        #cv2.putText(image, str(outputs.data), (40, 80),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4)\n",
    "        #cv2.putText(image, str(predicted.item()), (40, 120),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4) \n",
    "        # 0 for write/ 1 for erase/ 2 for others\n",
    "\n",
    "        if (predicted.item()==0): # write\n",
    "          cv2.putText(image, 'Writing', (10, 30),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4)\n",
    "          currunt_point = mp_drawing._normalized_to_pixel_coordinates(hand_landmarks.landmark[8].x, hand_landmarks.landmark[8].y, width, height)\n",
    "          \n",
    "          if (last_point):\n",
    "            cv2.line(board, last_point, currunt_point, (0), 4, 4)\n",
    "            last_point=currunt_point\n",
    "          else:\n",
    "            last_point=currunt_point\n",
    "\n",
    "        elif(predicted.item()==1): # erase\n",
    "          cv2.putText(image, 'Erasing', (10, 30),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4)\n",
    "\n",
    "          hand_landmarks.landmark[start_landmark].x=num_to01(hand_landmarks.landmark[start_landmark].x)\n",
    "          hand_landmarks.landmark[start_landmark].y=num_to01(hand_landmarks.landmark[start_landmark].y)\n",
    "          hand_landmarks.landmark[end_landmark].x=num_to01(hand_landmarks.landmark[end_landmark].x)\n",
    "          hand_landmarks.landmark[end_landmark].y=num_to01(hand_landmarks.landmark[end_landmark].y)\n",
    "          \n",
    "          (start_x,start_y)=mp_drawing._normalized_to_pixel_coordinates(hand_landmarks.landmark[start_landmark].x, hand_landmarks.landmark[start_landmark].y, width, height)\n",
    "          (end_x,end_y)=mp_drawing._normalized_to_pixel_coordinates(hand_landmarks.landmark[end_landmark].x, hand_landmarks.landmark[end_landmark].y, width, height)\n",
    "\n",
    "          cv2.rectangle(image, (start_x,start_y), (end_x,end_y), (255,0,0),4)\n",
    "\n",
    "          board[start_y:end_y,start_x:end_x]=np.logical_or(board[start_y:end_y,start_x:end_x],1)*255\n",
    "          last_point=[]\n",
    "          \n",
    "        else: # others\n",
    "          cv2.putText(image, 'Try writing/Erasing', (10, 30),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4)\n",
    "          last_point=[]\n",
    "\n",
    "    else: # without hands\n",
    "      cv2.putText(image, 'No hands', (10, 30),cv2.FONT_HERSHEY_COMPLEX,1,(255, 0, 0),1,4)\n",
    "      last_point=[]\n",
    "    \n",
    "    image=cv2.bitwise_and(image, image,mask=board)\n",
    "    cv2.imshow('Air writing', image)\n",
    "    if cv2.waitKey(100) & 0xFF == 27: # 按下 esc 退出\n",
    "      break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5173b21e1a45729408d013526dcf99a6e4399f996da2c503b1e76c6ee6c5129"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
