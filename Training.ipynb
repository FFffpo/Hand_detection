{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGestureDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        xy=np.loadtxt(filepath,delimiter=',',dtype=np.float32)\n",
    "        self.len=xy.shape[0]\n",
    "        self.x_data=torch.from_numpy(xy[:,:-1])\n",
    "        self.y_data=torch.from_numpy(xy[:,[-1]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index],self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "Training_set=HandGestureDataset('data\\Training_set\\Training_set.csv')\n",
    "train_loader=DataLoader(dataset=Training_set,shuffle=1,num_workers=0)\n",
    "\n",
    "Test_set=HandGestureDataset('data\\Test_set\\Test_set.csv')\n",
    "test_loader=DataLoader(dataset=Test_set,batch_size=22,shuffle=1,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.l1=torch.nn.Linear(63,40)\n",
    "        self.l2=torch.nn.Linear(40,20)\n",
    "        self.l3=torch.nn.Linear(20,10)\n",
    "        self.l4=torch.nn.Linear(10,1)\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.sigmoid(self.l1(x))\n",
    "        x=self.sigmoid(self.l2(x))\n",
    "        x=self.sigmoid(self.l3(x))\n",
    "        return self.sigmoid(self.l4(x))\n",
    "\n",
    "class NetTest(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetTest,self).__init__()\n",
    "        self.l1=torch.nn.Linear(63,128)\n",
    "        self.l2=torch.nn.Linear(128,64)\n",
    "        self.l3=torch.nn.Linear(64,1)\n",
    "\n",
    "        self.sigmoid=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.sigmoid(self.l1(x))\n",
    "        x=self.sigmoid(self.l2(x))\n",
    "        x=self.sigmoid(self.l3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "model=NetTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.BCELoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx, data in enumerate(train_loader,0):\n",
    "        inputs,target=data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "        if batch_idx % 40==39:\n",
    "            print('[%d, %5d] loss: %.3f'%(epoch+1,batch_idx+1,running_loss))\n",
    "            running_loss=0\n",
    "\n",
    "def test():\n",
    "    correct=0\n",
    "    total=0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs,labels=data\n",
    "            labels=labels.long()\n",
    "            \n",
    "            outputs=model(inputs)\n",
    "            predicted=torch.Tensor(22,1)\n",
    "            predicted=outputs.data>0.5\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted.long()==labels).sum().item()\n",
    "    \n",
    "    print('Accuracy on test set: %d %%'%(100*correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    40] loss: 28.217\n",
      "[1,    80] loss: 28.610\n",
      "[1,   120] loss: 27.952\n",
      "Accuracy on test set: 50 %\n",
      "[2,    40] loss: 27.682\n",
      "[2,    80] loss: 28.239\n",
      "[2,   120] loss: 27.848\n",
      "Accuracy on test set: 50 %\n",
      "[3,    40] loss: 28.076\n",
      "[3,    80] loss: 27.879\n",
      "[3,   120] loss: 28.013\n",
      "Accuracy on test set: 50 %\n",
      "[4,    40] loss: 27.679\n",
      "[4,    80] loss: 27.920\n",
      "[4,   120] loss: 28.025\n",
      "Accuracy on test set: 90 %\n",
      "[5,    40] loss: 27.517\n",
      "[5,    80] loss: 27.988\n",
      "[5,   120] loss: 27.834\n",
      "Accuracy on test set: 50 %\n",
      "[6,    40] loss: 27.832\n",
      "[6,    80] loss: 27.805\n",
      "[6,   120] loss: 27.769\n",
      "Accuracy on test set: 50 %\n",
      "[7,    40] loss: 27.724\n",
      "[7,    80] loss: 27.805\n",
      "[7,   120] loss: 27.702\n",
      "Accuracy on test set: 50 %\n",
      "[8,    40] loss: 27.725\n",
      "[8,    80] loss: 27.715\n",
      "[8,   120] loss: 27.683\n",
      "Accuracy on test set: 50 %\n",
      "[9,    40] loss: 27.654\n",
      "[9,    80] loss: 27.671\n",
      "[9,   120] loss: 27.540\n",
      "Accuracy on test set: 50 %\n",
      "[10,    40] loss: 26.961\n",
      "[10,    80] loss: 27.761\n",
      "[10,   120] loss: 27.124\n",
      "Accuracy on test set: 50 %\n",
      "[11,    40] loss: 27.653\n",
      "[11,    80] loss: 27.532\n",
      "[11,   120] loss: 27.481\n",
      "Accuracy on test set: 50 %\n",
      "[12,    40] loss: 27.436\n",
      "[12,    80] loss: 27.258\n",
      "[12,   120] loss: 27.515\n",
      "Accuracy on test set: 50 %\n",
      "[13,    40] loss: 27.410\n",
      "[13,    80] loss: 26.126\n",
      "[13,   120] loss: 27.726\n",
      "Accuracy on test set: 50 %\n",
      "[14,    40] loss: 27.396\n",
      "[14,    80] loss: 27.259\n",
      "[14,   120] loss: 27.080\n",
      "Accuracy on test set: 86 %\n",
      "[15,    40] loss: 26.640\n",
      "[15,    80] loss: 27.609\n",
      "[15,   120] loss: 26.928\n",
      "Accuracy on test set: 100 %\n",
      "[16,    40] loss: 26.744\n",
      "[16,    80] loss: 27.079\n",
      "[16,   120] loss: 26.462\n",
      "Accuracy on test set: 50 %\n",
      "[17,    40] loss: 26.764\n",
      "[17,    80] loss: 27.226\n",
      "[17,   120] loss: 26.303\n",
      "Accuracy on test set: 50 %\n",
      "[18,    40] loss: 26.823\n",
      "[18,    80] loss: 26.837\n",
      "[18,   120] loss: 26.369\n",
      "Accuracy on test set: 50 %\n",
      "[19,    40] loss: 26.824\n",
      "[19,    80] loss: 26.560\n",
      "[19,   120] loss: 26.486\n",
      "Accuracy on test set: 90 %\n",
      "[20,    40] loss: 26.497\n",
      "[20,    80] loss: 26.289\n",
      "[20,   120] loss: 26.266\n",
      "Accuracy on test set: 90 %\n",
      "[21,    40] loss: 26.314\n",
      "[21,    80] loss: 25.658\n",
      "[21,   120] loss: 26.371\n",
      "Accuracy on test set: 63 %\n",
      "[22,    40] loss: 25.846\n",
      "[22,    80] loss: 26.047\n",
      "[22,   120] loss: 26.077\n",
      "Accuracy on test set: 95 %\n",
      "[23,    40] loss: 25.847\n",
      "[23,    80] loss: 25.520\n",
      "[23,   120] loss: 25.536\n",
      "Accuracy on test set: 90 %\n",
      "[24,    40] loss: 25.555\n",
      "[24,    80] loss: 25.207\n",
      "[24,   120] loss: 25.461\n",
      "Accuracy on test set: 100 %\n",
      "[25,    40] loss: 25.038\n",
      "[25,    80] loss: 25.038\n",
      "[25,   120] loss: 24.927\n",
      "Accuracy on test set: 100 %\n",
      "[26,    40] loss: 24.719\n",
      "[26,    80] loss: 25.003\n",
      "[26,   120] loss: 24.261\n",
      "Accuracy on test set: 100 %\n",
      "[27,    40] loss: 24.029\n",
      "[27,    80] loss: 24.338\n",
      "[27,   120] loss: 24.328\n",
      "Accuracy on test set: 100 %\n",
      "[28,    40] loss: 23.703\n",
      "[28,    80] loss: 23.570\n",
      "[28,   120] loss: 23.605\n",
      "Accuracy on test set: 100 %\n",
      "[29,    40] loss: 22.201\n",
      "[29,    80] loss: 23.481\n",
      "[29,   120] loss: 22.621\n",
      "Accuracy on test set: 90 %\n",
      "[30,    40] loss: 23.523\n",
      "[30,    80] loss: 22.211\n",
      "[30,   120] loss: 22.100\n",
      "Accuracy on test set: 100 %\n",
      "[31,    40] loss: 22.206\n",
      "[31,    80] loss: 21.315\n",
      "[31,   120] loss: 21.883\n",
      "Accuracy on test set: 100 %\n",
      "[32,    40] loss: 21.350\n",
      "[32,    80] loss: 20.943\n",
      "[32,   120] loss: 20.386\n",
      "Accuracy on test set: 100 %\n",
      "[33,    40] loss: 19.641\n",
      "[33,    80] loss: 20.061\n",
      "[33,   120] loss: 20.215\n",
      "Accuracy on test set: 100 %\n",
      "[34,    40] loss: 19.489\n",
      "[34,    80] loss: 19.298\n",
      "[34,   120] loss: 18.623\n",
      "Accuracy on test set: 100 %\n",
      "[35,    40] loss: 18.782\n",
      "[35,    80] loss: 17.789\n",
      "[35,   120] loss: 17.854\n",
      "Accuracy on test set: 100 %\n",
      "[36,    40] loss: 18.034\n",
      "[36,    80] loss: 16.669\n",
      "[36,   120] loss: 16.244\n",
      "Accuracy on test set: 100 %\n",
      "[37,    40] loss: 16.806\n",
      "[37,    80] loss: 16.027\n",
      "[37,   120] loss: 14.828\n",
      "Accuracy on test set: 100 %\n",
      "[38,    40] loss: 15.004\n",
      "[38,    80] loss: 14.373\n",
      "[38,   120] loss: 14.574\n",
      "Accuracy on test set: 100 %\n",
      "[39,    40] loss: 13.326\n",
      "[39,    80] loss: 13.769\n",
      "[39,   120] loss: 13.838\n",
      "Accuracy on test set: 100 %\n",
      "[40,    40] loss: 13.912\n",
      "[40,    80] loss: 11.946\n",
      "[40,   120] loss: 11.325\n",
      "Accuracy on test set: 100 %\n",
      "[41,    40] loss: 10.979\n",
      "[41,    80] loss: 10.545\n",
      "[41,   120] loss: 12.675\n",
      "Accuracy on test set: 100 %\n",
      "[42,    40] loss: 11.070\n",
      "[42,    80] loss: 10.277\n",
      "[42,   120] loss: 10.241\n",
      "Accuracy on test set: 100 %\n",
      "[43,    40] loss: 10.065\n",
      "[43,    80] loss: 9.108\n",
      "[43,   120] loss: 9.541\n",
      "Accuracy on test set: 100 %\n",
      "[44,    40] loss: 9.918\n",
      "[44,    80] loss: 7.899\n",
      "[44,   120] loss: 8.402\n",
      "Accuracy on test set: 100 %\n",
      "[45,    40] loss: 9.317\n",
      "[45,    80] loss: 6.438\n",
      "[45,   120] loss: 7.946\n",
      "Accuracy on test set: 100 %\n",
      "[46,    40] loss: 6.596\n",
      "[46,    80] loss: 7.257\n",
      "[46,   120] loss: 7.872\n",
      "Accuracy on test set: 100 %\n",
      "[47,    40] loss: 6.219\n",
      "[47,    80] loss: 7.252\n",
      "[47,   120] loss: 6.469\n",
      "Accuracy on test set: 100 %\n",
      "[48,    40] loss: 5.377\n",
      "[48,    80] loss: 6.308\n",
      "[48,   120] loss: 6.592\n",
      "Accuracy on test set: 100 %\n",
      "[49,    40] loss: 6.082\n",
      "[49,    80] loss: 5.943\n",
      "[49,   120] loss: 4.503\n",
      "Accuracy on test set: 100 %\n",
      "[50,    40] loss: 5.599\n",
      "[50,    80] loss: 4.722\n",
      "[50,   120] loss: 5.221\n",
      "Accuracy on test set: 100 %\n",
      "[51,    40] loss: 4.590\n",
      "[51,    80] loss: 5.533\n",
      "[51,   120] loss: 4.168\n",
      "Accuracy on test set: 100 %\n",
      "[52,    40] loss: 4.448\n",
      "[52,    80] loss: 3.927\n",
      "[52,   120] loss: 4.597\n",
      "Accuracy on test set: 100 %\n",
      "[53,    40] loss: 4.445\n",
      "[53,    80] loss: 3.782\n",
      "[53,   120] loss: 4.041\n",
      "Accuracy on test set: 100 %\n",
      "[54,    40] loss: 4.543\n",
      "[54,    80] loss: 3.603\n",
      "[54,   120] loss: 3.261\n",
      "Accuracy on test set: 100 %\n",
      "[55,    40] loss: 3.278\n",
      "[55,    80] loss: 3.915\n",
      "[55,   120] loss: 3.483\n",
      "Accuracy on test set: 100 %\n",
      "[56,    40] loss: 3.180\n",
      "[56,    80] loss: 2.730\n",
      "[56,   120] loss: 3.486\n",
      "Accuracy on test set: 100 %\n",
      "[57,    40] loss: 2.921\n",
      "[57,    80] loss: 3.640\n",
      "[57,   120] loss: 2.761\n",
      "Accuracy on test set: 100 %\n",
      "[58,    40] loss: 3.373\n",
      "[58,    80] loss: 2.364\n",
      "[58,   120] loss: 2.982\n",
      "Accuracy on test set: 100 %\n",
      "[59,    40] loss: 2.568\n",
      "[59,    80] loss: 2.832\n",
      "[59,   120] loss: 2.838\n",
      "Accuracy on test set: 100 %\n",
      "[60,    40] loss: 2.920\n",
      "[60,    80] loss: 2.453\n",
      "[60,   120] loss: 2.330\n",
      "Accuracy on test set: 100 %\n",
      "[61,    40] loss: 3.277\n",
      "[61,    80] loss: 1.760\n",
      "[61,   120] loss: 2.294\n",
      "Accuracy on test set: 100 %\n",
      "[62,    40] loss: 2.606\n",
      "[62,    80] loss: 1.825\n",
      "[62,   120] loss: 2.527\n",
      "Accuracy on test set: 100 %\n",
      "[63,    40] loss: 2.262\n",
      "[63,    80] loss: 1.632\n",
      "[63,   120] loss: 2.630\n",
      "Accuracy on test set: 100 %\n",
      "[64,    40] loss: 1.881\n",
      "[64,    80] loss: 2.140\n",
      "[64,   120] loss: 2.214\n",
      "Accuracy on test set: 100 %\n",
      "[65,    40] loss: 1.586\n",
      "[65,    80] loss: 2.147\n",
      "[65,   120] loss: 2.131\n",
      "Accuracy on test set: 100 %\n",
      "[66,    40] loss: 1.847\n",
      "[66,    80] loss: 1.479\n",
      "[66,   120] loss: 2.316\n",
      "Accuracy on test set: 100 %\n",
      "[67,    40] loss: 2.140\n",
      "[67,    80] loss: 1.391\n",
      "[67,   120] loss: 1.889\n",
      "Accuracy on test set: 100 %\n",
      "[68,    40] loss: 1.510\n",
      "[68,    80] loss: 1.883\n",
      "[68,   120] loss: 1.754\n",
      "Accuracy on test set: 100 %\n",
      "[69,    40] loss: 1.745\n",
      "[69,    80] loss: 1.936\n",
      "[69,   120] loss: 1.253\n",
      "Accuracy on test set: 100 %\n",
      "[70,    40] loss: 1.695\n",
      "[70,    80] loss: 1.391\n",
      "[70,   120] loss: 1.648\n",
      "Accuracy on test set: 100 %\n",
      "[71,    40] loss: 1.258\n",
      "[71,    80] loss: 1.907\n",
      "[71,   120] loss: 1.378\n",
      "Accuracy on test set: 100 %\n",
      "[72,    40] loss: 1.010\n",
      "[72,    80] loss: 1.908\n",
      "[72,   120] loss: 1.432\n",
      "Accuracy on test set: 100 %\n",
      "[73,    40] loss: 1.094\n",
      "[73,    80] loss: 1.393\n",
      "[73,   120] loss: 1.673\n",
      "Accuracy on test set: 100 %\n",
      "[74,    40] loss: 1.472\n",
      "[74,    80] loss: 1.282\n",
      "[74,   120] loss: 1.176\n",
      "Accuracy on test set: 100 %\n",
      "[75,    40] loss: 1.275\n",
      "[75,    80] loss: 1.261\n",
      "[75,   120] loss: 1.331\n",
      "Accuracy on test set: 100 %\n",
      "[76,    40] loss: 1.193\n",
      "[76,    80] loss: 1.123\n",
      "[76,   120] loss: 1.350\n",
      "Accuracy on test set: 100 %\n",
      "[77,    40] loss: 1.316\n",
      "[77,    80] loss: 0.929\n",
      "[77,   120] loss: 1.340\n",
      "Accuracy on test set: 100 %\n",
      "[78,    40] loss: 1.155\n",
      "[78,    80] loss: 0.759\n",
      "[78,   120] loss: 1.529\n",
      "Accuracy on test set: 100 %\n",
      "[79,    40] loss: 0.903\n",
      "[79,    80] loss: 1.555\n",
      "[79,   120] loss: 0.858\n",
      "Accuracy on test set: 100 %\n",
      "[80,    40] loss: 1.265\n",
      "[80,    80] loss: 0.620\n",
      "[80,   120] loss: 1.354\n",
      "Accuracy on test set: 100 %\n",
      "[81,    40] loss: 1.187\n",
      "[81,    80] loss: 0.830\n",
      "[81,   120] loss: 1.126\n",
      "Accuracy on test set: 100 %\n",
      "[82,    40] loss: 1.183\n",
      "[82,    80] loss: 0.775\n",
      "[82,   120] loss: 1.088\n",
      "Accuracy on test set: 100 %\n",
      "[83,    40] loss: 0.735\n",
      "[83,    80] loss: 1.415\n",
      "[83,   120] loss: 0.764\n",
      "Accuracy on test set: 100 %\n",
      "[84,    40] loss: 0.951\n",
      "[84,    80] loss: 0.891\n",
      "[84,   120] loss: 0.916\n",
      "Accuracy on test set: 100 %\n",
      "[85,    40] loss: 0.834\n",
      "[85,    80] loss: 1.004\n",
      "[85,   120] loss: 0.868\n",
      "Accuracy on test set: 100 %\n",
      "[86,    40] loss: 1.279\n",
      "[86,    80] loss: 0.790\n",
      "[86,   120] loss: 0.628\n",
      "Accuracy on test set: 100 %\n",
      "[87,    40] loss: 0.655\n",
      "[87,    80] loss: 0.962\n",
      "[87,   120] loss: 0.995\n",
      "Accuracy on test set: 100 %\n",
      "[88,    40] loss: 0.821\n",
      "[88,    80] loss: 0.827\n",
      "[88,   120] loss: 0.817\n",
      "Accuracy on test set: 100 %\n",
      "[89,    40] loss: 0.802\n",
      "[89,    80] loss: 0.813\n",
      "[89,   120] loss: 0.846\n",
      "Accuracy on test set: 100 %\n",
      "[90,    40] loss: 0.659\n",
      "[90,    80] loss: 0.971\n",
      "[90,   120] loss: 0.778\n",
      "Accuracy on test set: 100 %\n",
      "[91,    40] loss: 0.675\n",
      "[91,    80] loss: 0.893\n",
      "[91,   120] loss: 0.771\n",
      "Accuracy on test set: 100 %\n",
      "[92,    40] loss: 0.912\n",
      "[92,    80] loss: 0.845\n",
      "[92,   120] loss: 0.474\n",
      "Accuracy on test set: 100 %\n",
      "[93,    40] loss: 0.590\n",
      "[93,    80] loss: 0.991\n",
      "[93,   120] loss: 0.637\n",
      "Accuracy on test set: 100 %\n",
      "[94,    40] loss: 0.698\n",
      "[94,    80] loss: 0.915\n",
      "[94,   120] loss: 0.517\n",
      "Accuracy on test set: 100 %\n",
      "[95,    40] loss: 0.545\n",
      "[95,    80] loss: 0.715\n",
      "[95,   120] loss: 0.815\n",
      "Accuracy on test set: 100 %\n",
      "[96,    40] loss: 0.458\n",
      "[96,    80] loss: 0.887\n",
      "[96,   120] loss: 0.716\n",
      "Accuracy on test set: 100 %\n",
      "[97,    40] loss: 0.658\n",
      "[97,    80] loss: 0.716\n",
      "[97,   120] loss: 0.620\n",
      "Accuracy on test set: 100 %\n",
      "[98,    40] loss: 0.600\n",
      "[98,    80] loss: 0.603\n",
      "[98,   120] loss: 0.775\n",
      "Accuracy on test set: 100 %\n",
      "[99,    40] loss: 0.717\n",
      "[99,    80] loss: 0.540\n",
      "[99,   120] loss: 0.681\n",
      "Accuracy on test set: 100 %\n",
      "[100,    40] loss: 0.857\n",
      "[100,    80] loss: 0.371\n",
      "[100,   120] loss: 0.669\n",
      "Accuracy on test set: 100 %\n",
      "[101,    40] loss: 0.737\n",
      "[101,    80] loss: 0.637\n",
      "[101,   120] loss: 0.472\n",
      "Accuracy on test set: 100 %\n",
      "[102,    40] loss: 0.676\n",
      "[102,    80] loss: 0.349\n",
      "[102,   120] loss: 0.789\n",
      "Accuracy on test set: 100 %\n",
      "[103,    40] loss: 0.642\n",
      "[103,    80] loss: 0.483\n",
      "[103,   120] loss: 0.632\n",
      "Accuracy on test set: 100 %\n",
      "[104,    40] loss: 0.543\n",
      "[104,    80] loss: 0.428\n",
      "[104,   120] loss: 0.763\n",
      "Accuracy on test set: 100 %\n",
      "[105,    40] loss: 0.478\n",
      "[105,    80] loss: 0.736\n",
      "[105,   120] loss: 0.476\n",
      "Accuracy on test set: 100 %\n",
      "[106,    40] loss: 0.587\n",
      "[106,    80] loss: 0.599\n",
      "[106,   120] loss: 0.477\n",
      "Accuracy on test set: 100 %\n",
      "[107,    40] loss: 0.577\n",
      "[107,    80] loss: 0.563\n",
      "[107,   120] loss: 0.492\n",
      "Accuracy on test set: 100 %\n",
      "[108,    40] loss: 0.442\n",
      "[108,    80] loss: 0.644\n",
      "[108,   120] loss: 0.498\n",
      "Accuracy on test set: 100 %\n",
      "[109,    40] loss: 0.684\n",
      "[109,    80] loss: 0.347\n",
      "[109,   120] loss: 0.511\n",
      "Accuracy on test set: 100 %\n",
      "[110,    40] loss: 0.494\n",
      "[110,    80] loss: 0.424\n",
      "[110,   120] loss: 0.619\n",
      "Accuracy on test set: 100 %\n",
      "[111,    40] loss: 0.365\n",
      "[111,    80] loss: 0.673\n",
      "[111,   120] loss: 0.467\n",
      "Accuracy on test set: 100 %\n",
      "[112,    40] loss: 0.362\n",
      "[112,    80] loss: 0.572\n",
      "[112,   120] loss: 0.540\n",
      "Accuracy on test set: 100 %\n",
      "[113,    40] loss: 0.439\n",
      "[113,    80] loss: 0.405\n",
      "[113,   120] loss: 0.609\n",
      "Accuracy on test set: 100 %\n",
      "[114,    40] loss: 0.525\n",
      "[114,    80] loss: 0.426\n",
      "[114,   120] loss: 0.471\n",
      "Accuracy on test set: 100 %\n",
      "[115,    40] loss: 0.465\n",
      "[115,    80] loss: 0.671\n",
      "[115,   120] loss: 0.268\n",
      "Accuracy on test set: 100 %\n",
      "[116,    40] loss: 0.433\n",
      "[116,    80] loss: 0.385\n",
      "[116,   120] loss: 0.555\n",
      "Accuracy on test set: 100 %\n",
      "[117,    40] loss: 0.452\n",
      "[117,    80] loss: 0.550\n",
      "[117,   120] loss: 0.325\n",
      "Accuracy on test set: 100 %\n",
      "[118,    40] loss: 0.411\n",
      "[118,    80] loss: 0.396\n",
      "[118,   120] loss: 0.479\n",
      "Accuracy on test set: 100 %\n",
      "[119,    40] loss: 0.463\n",
      "[119,    80] loss: 0.629\n",
      "[119,   120] loss: 0.217\n",
      "Accuracy on test set: 100 %\n",
      "[120,    40] loss: 0.590\n",
      "[120,    80] loss: 0.287\n",
      "[120,   120] loss: 0.412\n",
      "Accuracy on test set: 100 %\n",
      "[121,    40] loss: 0.267\n",
      "[121,    80] loss: 0.355\n",
      "[121,   120] loss: 0.641\n",
      "Accuracy on test set: 100 %\n",
      "[122,    40] loss: 0.560\n",
      "[122,    80] loss: 0.325\n",
      "[122,   120] loss: 0.358\n",
      "Accuracy on test set: 100 %\n",
      "[123,    40] loss: 0.472\n",
      "[123,    80] loss: 0.217\n",
      "[123,   120] loss: 0.532\n",
      "Accuracy on test set: 100 %\n",
      "[124,    40] loss: 0.472\n",
      "[124,    80] loss: 0.363\n",
      "[124,   120] loss: 0.360\n",
      "Accuracy on test set: 100 %\n",
      "[125,    40] loss: 0.408\n",
      "[125,    80] loss: 0.525\n",
      "[125,   120] loss: 0.250\n",
      "Accuracy on test set: 100 %\n",
      "[126,    40] loss: 0.344\n",
      "[126,    80] loss: 0.372\n",
      "[126,   120] loss: 0.439\n",
      "Accuracy on test set: 100 %\n",
      "[127,    40] loss: 0.373\n",
      "[127,    80] loss: 0.461\n",
      "[127,   120] loss: 0.314\n",
      "Accuracy on test set: 100 %\n",
      "[128,    40] loss: 0.347\n",
      "[128,    80] loss: 0.459\n",
      "[128,   120] loss: 0.327\n",
      "Accuracy on test set: 100 %\n",
      "[129,    40] loss: 0.234\n",
      "[129,    80] loss: 0.507\n",
      "[129,   120] loss: 0.374\n",
      "Accuracy on test set: 100 %\n",
      "[130,    40] loss: 0.385\n",
      "[130,    80] loss: 0.332\n",
      "[130,   120] loss: 0.365\n",
      "Accuracy on test set: 100 %\n",
      "[131,    40] loss: 0.352\n",
      "[131,    80] loss: 0.322\n",
      "[131,   120] loss: 0.360\n",
      "Accuracy on test set: 100 %\n",
      "[132,    40] loss: 0.533\n",
      "[132,    80] loss: 0.179\n",
      "[132,   120] loss: 0.346\n",
      "Accuracy on test set: 100 %\n",
      "[133,    40] loss: 0.349\n",
      "[133,    80] loss: 0.194\n",
      "[133,   120] loss: 0.433\n",
      "Accuracy on test set: 100 %\n",
      "[134,    40] loss: 0.242\n",
      "[134,    80] loss: 0.345\n",
      "[134,   120] loss: 0.450\n",
      "Accuracy on test set: 100 %\n",
      "[135,    40] loss: 0.357\n",
      "[135,    80] loss: 0.390\n",
      "[135,   120] loss: 0.273\n",
      "Accuracy on test set: 100 %\n",
      "[136,    40] loss: 0.411\n",
      "[136,    80] loss: 0.307\n",
      "[136,   120] loss: 0.288\n",
      "Accuracy on test set: 100 %\n",
      "[137,    40] loss: 0.359\n",
      "[137,    80] loss: 0.361\n",
      "[137,   120] loss: 0.271\n",
      "Accuracy on test set: 100 %\n",
      "[138,    40] loss: 0.496\n",
      "[138,    80] loss: 0.183\n",
      "[138,   120] loss: 0.288\n",
      "Accuracy on test set: 100 %\n",
      "[139,    40] loss: 0.176\n",
      "[139,    80] loss: 0.453\n",
      "[139,   120] loss: 0.300\n",
      "Accuracy on test set: 100 %\n",
      "[140,    40] loss: 0.373\n",
      "[140,    80] loss: 0.298\n",
      "[140,   120] loss: 0.285\n",
      "Accuracy on test set: 100 %\n",
      "[141,    40] loss: 0.259\n",
      "[141,    80] loss: 0.356\n",
      "[141,   120] loss: 0.315\n",
      "Accuracy on test set: 100 %\n",
      "[142,    40] loss: 0.309\n",
      "[142,    80] loss: 0.378\n",
      "[142,   120] loss: 0.220\n",
      "Accuracy on test set: 100 %\n",
      "[143,    40] loss: 0.231\n",
      "[143,    80] loss: 0.431\n",
      "[143,   120] loss: 0.249\n",
      "Accuracy on test set: 100 %\n",
      "[144,    40] loss: 0.331\n",
      "[144,    80] loss: 0.186\n",
      "[144,   120] loss: 0.361\n",
      "Accuracy on test set: 100 %\n",
      "[145,    40] loss: 0.294\n",
      "[145,    80] loss: 0.385\n",
      "[145,   120] loss: 0.211\n",
      "Accuracy on test set: 100 %\n",
      "[146,    40] loss: 0.311\n",
      "[146,    80] loss: 0.263\n",
      "[146,   120] loss: 0.283\n",
      "Accuracy on test set: 100 %\n",
      "[147,    40] loss: 0.261\n",
      "[147,    80] loss: 0.331\n",
      "[147,   120] loss: 0.278\n",
      "Accuracy on test set: 100 %\n",
      "[148,    40] loss: 0.222\n",
      "[148,    80] loss: 0.389\n",
      "[148,   120] loss: 0.241\n",
      "Accuracy on test set: 100 %\n",
      "[149,    40] loss: 0.254\n",
      "[149,    80] loss: 0.293\n",
      "[149,   120] loss: 0.267\n",
      "Accuracy on test set: 100 %\n",
      "[150,    40] loss: 0.208\n",
      "[150,    80] loss: 0.364\n",
      "[150,   120] loss: 0.266\n",
      "Accuracy on test set: 100 %\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    for epoch in range(150):\n",
    "        train(epoch)\n",
    "        test()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type NetTest. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,f='model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
