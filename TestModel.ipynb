{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\r\n",
    "import mediapipe as mp\r\n",
    "\r\n",
    "import json\r\n",
    "import pandas as pd\r\n",
    "from os import listdir\r\n",
    "import re\r\n",
    "import time\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n",
    "\r\n",
    "mp_drawing = mp.solutions.drawing_utils\r\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\r\n",
    "mp_hands = mp.solutions.hands"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Net(torch.nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Net,self).__init__()\r\n",
    "        self.l1=torch.nn.Linear(63,40)\r\n",
    "        self.l2=torch.nn.Linear(40,20)\r\n",
    "        self.l3=torch.nn.Linear(20,10)\r\n",
    "        self.l4=torch.nn.Linear(10,1)\r\n",
    "        self.sigmoid=torch.nn.Sigmoid()\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        x=self.sigmoid(self.l1(x))\r\n",
    "        x=self.sigmoid(self.l2(x))\r\n",
    "        x=self.sigmoid(self.l3(x))\r\n",
    "        return self.sigmoid(self.l4(x))\r\n",
    "\r\n",
    "model=torch.load('model.pkl')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def StandardScaler(x):\r\n",
    "    '''数据标准化，且以21个骨骼点的第一个为原点'''\r\n",
    "    x_array=np.array(x)\r\n",
    "    x_array-=x_array[0]\r\n",
    "\r\n",
    "    mean=np.mean(x_array)\r\n",
    "    std=np.std(x_array)\r\n",
    "\r\n",
    "    x_array-=mean\r\n",
    "    x_array/=std\r\n",
    "\r\n",
    "    x_corr=x_array.tolist()\r\n",
    "\r\n",
    "    return x_corr\r\n",
    "\r\n",
    "\r\n",
    "def Landmarks2array(hand_landmarks):\r\n",
    "    '''将mediapipe的输出变为numpy.array形式(63, )'''\r\n",
    "    # ->txt\r\n",
    "    with open('temp/temp.txt','w') as f:\r\n",
    "        print(hand_landmarks,file=f)\r\n",
    "\r\n",
    "    # txt->json\r\n",
    "    seq = re.compile(\":\")\r\n",
    "    result = []\r\n",
    "\r\n",
    "    with open('temp/temp.txt') as f:\r\n",
    "        for line in f:\r\n",
    "            lst = seq.split(line.strip())\r\n",
    "            if (len(lst)>=2): \r\n",
    "                item = {str(lst[0]): float(lst[1])}\r\n",
    "                result.append(item)    \r\n",
    "\r\n",
    "    with open('temp/temp.json', 'w') as dump_f:\r\n",
    "        json.dump(result,dump_f)\r\n",
    "        \r\n",
    "    # json->array\r\n",
    "    with open('temp/temp.json') as f:\r\n",
    "        data = json.load(f)\r\n",
    "        x = []\r\n",
    "        y = []\r\n",
    "        z = []\r\n",
    "        xyz=[]\r\n",
    "        for pt in data:\r\n",
    "            if 'x' in pt: x.append(pt['x'])\r\n",
    "            if 'y' in pt: y.append(pt['y'])\r\n",
    "            if 'z' in pt: z.append(pt['z'])\r\n",
    "        \r\n",
    "        # 数据标准化\r\n",
    "        x=StandardScaler(x)\r\n",
    "        y=StandardScaler(y)\r\n",
    "        z=StandardScaler(z)\r\n",
    "\r\n",
    "    xyz=x+y+z # 将21*3=63个值排成一列，便于下一步处理\r\n",
    "\r\n",
    "    return np.array(xyz)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "cap = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5, max_num_hands=1) as hands:\r\n",
    "  while cap.isOpened():\r\n",
    "    success, image = cap.read()\r\n",
    "    if not success:\r\n",
    "      print(\"Ignoring empty camera frame.\")\r\n",
    "      # If loading a video, use 'break' instead of 'continue'.\r\n",
    "      continue\r\n",
    "\r\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert the BGR image to RGB.\r\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\r\n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\r\n",
    "    image.flags.writeable = False\r\n",
    "    results = hands.process(image)\r\n",
    "\r\n",
    "    # Draw the hand annotations on the image.\r\n",
    "    image.flags.writeable = True\r\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\r\n",
    "    if results.multi_hand_landmarks:\r\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\r\n",
    "        mp_drawing.draw_landmarks(\r\n",
    "            image,\r\n",
    "            hand_landmarks,\r\n",
    "            mp_hands.HAND_CONNECTIONS,\r\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\r\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\r\n",
    "        \r\n",
    "        #if cv2.waitKey(100) & 0xFF == ord('t'): # 按下 t 键进行一次检测\r\n",
    "          #inputs=torch.from_numpy(Landmarks2array(hand_landmarks)).float()\r\n",
    "          \r\n",
    "          #outputs=model(inputs)\r\n",
    "          #predicted=(outputs.data>0.5).long()\r\n",
    "          #print(predicted)\r\n",
    "\r\n",
    "        inputs=torch.from_numpy(Landmarks2array(hand_landmarks)).float()\r\n",
    "        outputs=model(inputs)\r\n",
    "        cv2.putText(image, str(outputs.data), (40, 80),cv2.FONT_HERSHEY_COMPLEX,1,(0, 255, 0),1,4)\r\n",
    "        \r\n",
    "\r\n",
    "    cv2.imshow('MediaPipe Hands', image)\r\n",
    "    if cv2.waitKey(100) & 0xFF == 27: # 按下 esc 退出\r\n",
    "      break\r\n",
    "cap.release()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit"
  },
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}